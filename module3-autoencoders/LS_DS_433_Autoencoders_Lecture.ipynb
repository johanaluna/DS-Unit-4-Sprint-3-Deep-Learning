{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 3, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "> An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner.[1][2] The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal “noise”. Along with the reduction side, a reconstructing side is learnt, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input, hence its name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "*At the end of the lecture you should be to*:\n",
    "* <a href=\"#p1\">Part 1</a>: Describe the componenets of an autoencoder\n",
    "* <a href=\"#p2\">Part 2</a>: Train an autoencoder\n",
    "* <a href=\"#p3\">Part 3</a>: Apply an autoenocder to a basic information retrieval problem\n",
    "\n",
    "__Problem:__ Is it possible to automatically represent an image as a fixed-sized vector even if it isn’t labeled?\n",
    "\n",
    "__Solution:__ Use an autoencoder\n",
    "\n",
    "Why do we need to represent an image as a fixed-sized vector do you ask? \n",
    "\n",
    "* __Information Retrieval__\n",
    "    - [Reverse Image Search](https://en.wikipedia.org/wiki/Reverse_image_search)\n",
    "    - [Recommendation Systems - Content Based Filtering](https://en.wikipedia.org/wiki/Recommender_system#Content-based_filtering)\n",
    "* __Dimensionality Reduction__\n",
    "    - [Feature Extraction](https://www.kaggle.com/c/vsb-power-line-fault-detection/discussion/78285)\n",
    "    - [Manifold Learning](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)\n",
    "\n",
    "We've already seen *representation learning* when we talked about word embedding modelings during our NLP week. Today we're going to achieve a similiar goal on images using *autoencoders*. An autoencoder is a neural network that is trained to attempt to copy its input to its output. Usually they are restricted in ways that allow them to copy only approximately. The model often learns useful properties of the data, because it is forced to prioritize which aspecs of the input should be copied. The properties of autoencoders have made them an important part of modern generative modeling approaches. Consider autoencoders a special case of feed-forward networks (the kind we've been studying); backpropagation and gradient descent still work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Architecture (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The *encoder* compresses the input data and the *decoder* does the reverse to produce the uncompressed version of the data to create a reconstruction of the input as accurately as possible:\n",
    "\n",
    "<img src='https://miro.medium.com/max/1400/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png' width=800/>\n",
    "\n",
    "The learning process gis described simply as minimizing a loss function: \n",
    "$ L(x, g(f(x))) $\n",
    "\n",
    "- $L$ is a loss function penalizing $g(f(x))$ for being dissimiliar from $x$ (such as mean squared error)\n",
    "- $f$ is the encoder function\n",
    "- $g$ is the decoder function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along\n",
    "### Extremely Simple Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "#specify a layer and then in a parethesis the input layer\n",
    "\n",
    "encoded = Dense(encoding_dim ,activation='sigmoid')(input_img)\n",
    "\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "\n",
    "decoded = Dense(784 ,activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img,decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "\n",
    "# retrieve the last layer of the autoencoder model\n",
    "\n",
    "# create the decoder model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1113 17:53:04.501349 139806021412672 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.6946 - val_loss: 0.6944\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6941 - val_loss: 0.6939\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6936 - val_loss: 0.6934\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6932 - val_loss: 0.6929\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6927 - val_loss: 0.6925\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.6922 - val_loss: 0.6920\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6917 - val_loss: 0.6915\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6912 - val_loss: 0.6910\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6908 - val_loss: 0.6906\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6903 - val_loss: 0.6901\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6898 - val_loss: 0.6896\n",
      "Epoch 12/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6894 - val_loss: 0.6891\n",
      "Epoch 13/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6889 - val_loss: 0.6887\n",
      "Epoch 14/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6884 - val_loss: 0.6882\n",
      "Epoch 15/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6879 - val_loss: 0.6877\n",
      "Epoch 16/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6875 - val_loss: 0.6873\n",
      "Epoch 17/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6870 - val_loss: 0.6868\n",
      "Epoch 18/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6865 - val_loss: 0.6863\n",
      "Epoch 19/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6861 - val_loss: 0.6859\n",
      "Epoch 20/1000\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.6856 - val_loss: 0.6854\n",
      "Epoch 21/1000\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.6851 - val_loss: 0.6849\n",
      "Epoch 22/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6847 - val_loss: 0.6845\n",
      "Epoch 23/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6842 - val_loss: 0.6840\n",
      "Epoch 24/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6837 - val_loss: 0.6835\n",
      "Epoch 25/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6833 - val_loss: 0.6831\n",
      "Epoch 26/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6828 - val_loss: 0.6826\n",
      "Epoch 27/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6823 - val_loss: 0.6821\n",
      "Epoch 28/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6819 - val_loss: 0.6817\n",
      "Epoch 29/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6814 - val_loss: 0.6812\n",
      "Epoch 30/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6809 - val_loss: 0.6807\n",
      "Epoch 31/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6805 - val_loss: 0.6803\n",
      "Epoch 32/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6800 - val_loss: 0.6798\n",
      "Epoch 33/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6795 - val_loss: 0.6793\n",
      "Epoch 34/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6791 - val_loss: 0.6789\n",
      "Epoch 35/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6786 - val_loss: 0.6784\n",
      "Epoch 36/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6781 - val_loss: 0.6779\n",
      "Epoch 37/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6777 - val_loss: 0.6775\n",
      "Epoch 38/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6772 - val_loss: 0.6770\n",
      "Epoch 39/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6767 - val_loss: 0.6765\n",
      "Epoch 40/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6763 - val_loss: 0.6761\n",
      "Epoch 41/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6758 - val_loss: 0.6756\n",
      "Epoch 42/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6753 - val_loss: 0.6751\n",
      "Epoch 43/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6749 - val_loss: 0.6746\n",
      "Epoch 44/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6744 - val_loss: 0.6742\n",
      "Epoch 45/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6739 - val_loss: 0.6737\n",
      "Epoch 46/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6735 - val_loss: 0.6732\n",
      "Epoch 47/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6730 - val_loss: 0.6728\n",
      "Epoch 48/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6725 - val_loss: 0.6723\n",
      "Epoch 49/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6721 - val_loss: 0.6718\n",
      "Epoch 50/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6716 - val_loss: 0.6714\n",
      "Epoch 51/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6711 - val_loss: 0.6709\n",
      "Epoch 52/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6706 - val_loss: 0.6704\n",
      "Epoch 53/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6702 - val_loss: 0.6699\n",
      "Epoch 54/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6697 - val_loss: 0.6695\n",
      "Epoch 55/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6692 - val_loss: 0.6690\n",
      "Epoch 56/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6687 - val_loss: 0.6685\n",
      "Epoch 57/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6683 - val_loss: 0.6680\n",
      "Epoch 58/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6678 - val_loss: 0.6676\n",
      "Epoch 59/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6673 - val_loss: 0.6671\n",
      "Epoch 60/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6668 - val_loss: 0.6666\n",
      "Epoch 61/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6664 - val_loss: 0.6661\n",
      "Epoch 62/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6659 - val_loss: 0.6656\n",
      "Epoch 63/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6654 - val_loss: 0.6652\n",
      "Epoch 64/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6649 - val_loss: 0.6647\n",
      "Epoch 65/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6644 - val_loss: 0.6642\n",
      "Epoch 66/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6640 - val_loss: 0.6637\n",
      "Epoch 67/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6635 - val_loss: 0.6632\n",
      "Epoch 68/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6630 - val_loss: 0.6627\n",
      "Epoch 69/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6625 - val_loss: 0.6623\n",
      "Epoch 70/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6620 - val_loss: 0.6618\n",
      "Epoch 71/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6615 - val_loss: 0.6613\n",
      "Epoch 72/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6610 - val_loss: 0.6608\n",
      "Epoch 73/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6606 - val_loss: 0.6603\n",
      "Epoch 74/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6601 - val_loss: 0.6598\n",
      "Epoch 75/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6596 - val_loss: 0.6593\n",
      "Epoch 76/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6591 - val_loss: 0.6588\n",
      "Epoch 77/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6586 - val_loss: 0.6583\n",
      "Epoch 78/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6581 - val_loss: 0.6578\n",
      "Epoch 79/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6576 - val_loss: 0.6573\n",
      "Epoch 80/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6571 - val_loss: 0.6568\n",
      "Epoch 81/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6566 - val_loss: 0.6563\n",
      "Epoch 82/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6561 - val_loss: 0.6558\n",
      "Epoch 83/1000\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.6556 - val_loss: 0.6553\n",
      "Epoch 84/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6551 - val_loss: 0.6548\n",
      "Epoch 85/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6546 - val_loss: 0.6543\n",
      "Epoch 86/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6541 - val_loss: 0.6538\n",
      "Epoch 87/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6536 - val_loss: 0.6533\n",
      "Epoch 88/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6531 - val_loss: 0.6528\n",
      "Epoch 89/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6526 - val_loss: 0.6523\n",
      "Epoch 90/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6521 - val_loss: 0.6518\n",
      "Epoch 91/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6515 - val_loss: 0.6513\n",
      "Epoch 92/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6510 - val_loss: 0.6507\n",
      "Epoch 93/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6505 - val_loss: 0.6502\n",
      "Epoch 94/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6500 - val_loss: 0.6497\n",
      "Epoch 95/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6495 - val_loss: 0.6492\n",
      "Epoch 96/1000\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.6490 - val_loss: 0.6487\n",
      "Epoch 97/1000\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.6485 - val_loss: 0.6482\n",
      "Epoch 98/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6479 - val_loss: 0.6476\n",
      "Epoch 99/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6474 - val_loss: 0.6471\n",
      "Epoch 100/1000\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.6469 - val_loss: 0.6466\n",
      "Epoch 101/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6464 - val_loss: 0.6460\n",
      "Epoch 102/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6458 - val_loss: 0.6455\n",
      "Epoch 103/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6453 - val_loss: 0.6450\n",
      "Epoch 104/1000\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.6448 - val_loss: 0.6445\n",
      "Epoch 105/1000\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.6442"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-db496f60269a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 verbose = True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    410\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# wandb.init(project=\"mnist_autoencoder\", entity=\"ds5\")\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=1000,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "decoded_imgs = autoencoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Expected to talk about the components of autoencoder and their purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an Autoencoder (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "As long as our architecture maintains an hourglass shape, we can continue to add layers and create a deeper network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(784,))# This is the first layer of our network \n",
    "encoded = Dense (128, activation='relu')(input_img)\n",
    "encoded = Dense (64, activation='relu')(encoded)\n",
    "encoded = Dense (32, activation='relu')(encoded) # fully dehydrated layer \n",
    "\n",
    "decoded = Dense (64, activation='relu')(encoded)\n",
    "decoded = Dense (128, activation='relu')(decoded)\n",
    "decoded = Dense (784, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.4150 - val_loss: 0.3074\n",
      "Epoch 2/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2893 - val_loss: 0.2784\n",
      "Epoch 3/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2743 - val_loss: 0.2709\n",
      "Epoch 4/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2694 - val_loss: 0.2678\n",
      "Epoch 5/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2671 - val_loss: 0.2661\n",
      "Epoch 6/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2659 - val_loss: 0.2652\n",
      "Epoch 7/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2651 - val_loss: 0.2646\n",
      "Epoch 8/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2646 - val_loss: 0.2642\n",
      "Epoch 9/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2643 - val_loss: 0.2638\n",
      "Epoch 10/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2640 - val_loss: 0.2636\n",
      "Epoch 11/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2638 - val_loss: 0.2634\n",
      "Epoch 12/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2637 - val_loss: 0.2633\n",
      "Epoch 13/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2635 - val_loss: 0.2632\n",
      "Epoch 14/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2635 - val_loss: 0.2631\n",
      "Epoch 15/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2634 - val_loss: 0.2630\n",
      "Epoch 16/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2633 - val_loss: 0.2630\n",
      "Epoch 17/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2633 - val_loss: 0.2630\n",
      "Epoch 18/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2632 - val_loss: 0.2629\n",
      "Epoch 19/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2632 - val_loss: 0.2628\n",
      "Epoch 20/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2631 - val_loss: 0.2628\n",
      "Epoch 21/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2631 - val_loss: 0.2628\n",
      "Epoch 22/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2631 - val_loss: 0.2628\n",
      "Epoch 23/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2630 - val_loss: 0.2626\n",
      "Epoch 24/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2622 - val_loss: 0.2609\n",
      "Epoch 25/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2599 - val_loss: 0.2580\n",
      "Epoch 26/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2567 - val_loss: 0.2550\n",
      "Epoch 27/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2541 - val_loss: 0.2527\n",
      "Epoch 28/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2520 - val_loss: 0.2507\n",
      "Epoch 29/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2502 - val_loss: 0.2490\n",
      "Epoch 30/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2486 - val_loss: 0.2473\n",
      "Epoch 31/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2465 - val_loss: 0.2448\n",
      "Epoch 32/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2438 - val_loss: 0.2419\n",
      "Epoch 33/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2411 - val_loss: 0.2391\n",
      "Epoch 34/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2382 - val_loss: 0.2361\n",
      "Epoch 35/500\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2352 - val_loss: 0.2331\n",
      "Epoch 36/500\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2325 - val_loss: 0.2305\n",
      "Epoch 37/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2299 - val_loss: 0.2279\n",
      "Epoch 38/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2270 - val_loss: 0.2246\n",
      "Epoch 39/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2237 - val_loss: 0.2213\n",
      "Epoch 40/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2205 - val_loss: 0.2182\n",
      "Epoch 41/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2176 - val_loss: 0.2154\n",
      "Epoch 42/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2147 - val_loss: 0.2125\n",
      "Epoch 43/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2119 - val_loss: 0.2097\n",
      "Epoch 44/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2092 - val_loss: 0.2072\n",
      "Epoch 45/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2069 - val_loss: 0.2050\n",
      "Epoch 46/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2048 - val_loss: 0.2031\n",
      "Epoch 47/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2030 - val_loss: 0.2014\n",
      "Epoch 48/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2014 - val_loss: 0.1999\n",
      "Epoch 49/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2000 - val_loss: 0.1985\n",
      "Epoch 50/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1987 - val_loss: 0.1972\n",
      "Epoch 51/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1975 - val_loss: 0.1960\n",
      "Epoch 52/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1961 - val_loss: 0.1945\n",
      "Epoch 53/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1946 - val_loss: 0.1929\n",
      "Epoch 54/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1930 - val_loss: 0.1913\n",
      "Epoch 55/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1915 - val_loss: 0.1899\n",
      "Epoch 56/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1902 - val_loss: 0.1886\n",
      "Epoch 57/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1890 - val_loss: 0.1876\n",
      "Epoch 58/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1880 - val_loss: 0.1865\n",
      "Epoch 59/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1870 - val_loss: 0.1856\n",
      "Epoch 60/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1862 - val_loss: 0.1848\n",
      "Epoch 61/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1854 - val_loss: 0.1840\n",
      "Epoch 62/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1846 - val_loss: 0.1832\n",
      "Epoch 63/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1839 - val_loss: 0.1826\n",
      "Epoch 64/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1833 - val_loss: 0.1819\n",
      "Epoch 65/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1826 - val_loss: 0.1813\n",
      "Epoch 66/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1820 - val_loss: 0.1807\n",
      "Epoch 67/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1815 - val_loss: 0.1801\n",
      "Epoch 68/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1809 - val_loss: 0.1796\n",
      "Epoch 69/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1804 - val_loss: 0.1790\n",
      "Epoch 70/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1799 - val_loss: 0.1785\n",
      "Epoch 71/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1793 - val_loss: 0.1778\n",
      "Epoch 72/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1784 - val_loss: 0.1767\n",
      "Epoch 73/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1773 - val_loss: 0.1757\n",
      "Epoch 74/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1764 - val_loss: 0.1749\n",
      "Epoch 75/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1756 - val_loss: 0.1741\n",
      "Epoch 76/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1749 - val_loss: 0.1735\n",
      "Epoch 77/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1743 - val_loss: 0.1729\n",
      "Epoch 78/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1738 - val_loss: 0.1723\n",
      "Epoch 79/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1733 - val_loss: 0.1718\n",
      "Epoch 80/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1728 - val_loss: 0.1714\n",
      "Epoch 81/500\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.1723 - val_loss: 0.1709\n",
      "Epoch 82/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1719 - val_loss: 0.1705\n",
      "Epoch 83/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1715 - val_loss: 0.1701\n",
      "Epoch 84/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1711 - val_loss: 0.1697\n",
      "Epoch 85/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1707 - val_loss: 0.1693\n",
      "Epoch 86/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1704 - val_loss: 0.1690\n",
      "Epoch 87/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1700 - val_loss: 0.1686\n",
      "Epoch 88/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1697 - val_loss: 0.1683\n",
      "Epoch 89/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1694 - val_loss: 0.1680\n",
      "Epoch 90/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1691 - val_loss: 0.1677\n",
      "Epoch 91/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1688 - val_loss: 0.1674\n",
      "Epoch 92/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1685 - val_loss: 0.1671\n",
      "Epoch 93/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1682 - val_loss: 0.1668\n",
      "Epoch 94/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1680 - val_loss: 0.1666\n",
      "Epoch 95/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1677 - val_loss: 0.1664\n",
      "Epoch 96/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1675 - val_loss: 0.1661\n",
      "Epoch 97/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1672 - val_loss: 0.1659\n",
      "Epoch 98/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1670 - val_loss: 0.1657\n",
      "Epoch 99/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1668 - val_loss: 0.1655\n",
      "Epoch 100/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1666 - val_loss: 0.1653\n",
      "Epoch 101/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1664 - val_loss: 0.1650\n",
      "Epoch 102/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1662 - val_loss: 0.1649\n",
      "Epoch 103/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1660 - val_loss: 0.1646\n",
      "Epoch 104/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1657 - val_loss: 0.1641\n",
      "Epoch 105/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1650 - val_loss: 0.1633\n",
      "Epoch 106/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1642 - val_loss: 0.1626\n",
      "Epoch 107/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1636 - val_loss: 0.1620\n",
      "Epoch 108/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1628 - val_loss: 0.1611\n",
      "Epoch 109/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1618 - val_loss: 0.1601\n",
      "Epoch 110/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1609 - val_loss: 0.1592\n",
      "Epoch 111/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1601 - val_loss: 0.1586\n",
      "Epoch 112/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1595 - val_loss: 0.1580\n",
      "Epoch 113/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1590 - val_loss: 0.1575\n",
      "Epoch 114/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1585 - val_loss: 0.1571\n",
      "Epoch 115/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1581 - val_loss: 0.1567\n",
      "Epoch 116/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1577 - val_loss: 0.1563\n",
      "Epoch 117/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1574 - val_loss: 0.1560\n",
      "Epoch 118/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1571 - val_loss: 0.1557\n",
      "Epoch 119/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1568 - val_loss: 0.1554\n",
      "Epoch 120/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1565 - val_loss: 0.1552\n",
      "Epoch 121/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1563 - val_loss: 0.1549\n",
      "Epoch 122/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1560 - val_loss: 0.1547\n",
      "Epoch 123/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1558 - val_loss: 0.1545\n",
      "Epoch 124/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1556 - val_loss: 0.1543\n",
      "Epoch 125/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1554 - val_loss: 0.1541\n",
      "Epoch 126/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1552 - val_loss: 0.1539\n",
      "Epoch 127/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1550 - val_loss: 0.1537\n",
      "Epoch 128/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1548 - val_loss: 0.1535\n",
      "Epoch 129/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1547 - val_loss: 0.1534\n",
      "Epoch 130/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1545 - val_loss: 0.1532\n",
      "Epoch 131/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1544 - val_loss: 0.1531\n",
      "Epoch 132/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1542 - val_loss: 0.1529\n",
      "Epoch 133/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1541 - val_loss: 0.1528\n",
      "Epoch 134/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1539 - val_loss: 0.1527\n",
      "Epoch 135/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1538 - val_loss: 0.1526\n",
      "Epoch 136/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1537 - val_loss: 0.1524\n",
      "Epoch 137/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1536 - val_loss: 0.1523\n",
      "Epoch 138/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1534 - val_loss: 0.1522\n",
      "Epoch 139/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1533 - val_loss: 0.1521\n",
      "Epoch 140/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1532 - val_loss: 0.1520\n",
      "Epoch 141/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1531 - val_loss: 0.1519\n",
      "Epoch 142/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1530 - val_loss: 0.1518\n",
      "Epoch 143/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1529 - val_loss: 0.1517\n",
      "Epoch 144/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1528 - val_loss: 0.1514\n",
      "Epoch 145/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1525 - val_loss: 0.1511\n",
      "Epoch 146/500\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1520 - val_loss: 0.1505\n",
      "Epoch 147/500\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1514 - val_loss: 0.1500\n",
      "Epoch 148/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1508 - val_loss: 0.1493\n",
      "Epoch 149/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1498 - val_loss: 0.1480\n",
      "Epoch 150/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1485 - val_loss: 0.1466\n",
      "Epoch 151/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1470 - val_loss: 0.1451\n",
      "Epoch 152/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1457 - val_loss: 0.1438\n",
      "Epoch 153/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1443 - val_loss: 0.1424\n",
      "Epoch 154/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1429 - val_loss: 0.1409\n",
      "Epoch 155/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1413 - val_loss: 0.1393\n",
      "Epoch 156/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1398 - val_loss: 0.1378\n",
      "Epoch 157/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1383 - val_loss: 0.1363\n",
      "Epoch 158/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1367 - val_loss: 0.1347\n",
      "Epoch 159/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1352 - val_loss: 0.1332\n",
      "Epoch 160/500\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1337 - val_loss: 0.1318\n",
      "Epoch 161/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1324 - val_loss: 0.1304\n",
      "Epoch 162/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1310 - val_loss: 0.1291\n",
      "Epoch 163/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1297 - val_loss: 0.1277\n",
      "Epoch 164/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1283 - val_loss: 0.1264\n",
      "Epoch 165/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1271 - val_loss: 0.1252\n",
      "Epoch 166/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1259 - val_loss: 0.1240\n",
      "Epoch 167/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1247 - val_loss: 0.1229\n",
      "Epoch 168/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1236 - val_loss: 0.1217\n",
      "Epoch 169/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1224 - val_loss: 0.1206\n",
      "Epoch 170/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1214 - val_loss: 0.1196\n",
      "Epoch 171/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1203 - val_loss: 0.1185\n",
      "Epoch 172/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1193 - val_loss: 0.1175\n",
      "Epoch 173/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1183 - val_loss: 0.1164\n",
      "Epoch 174/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1172 - val_loss: 0.1154\n",
      "Epoch 175/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1162 - val_loss: 0.1144\n",
      "Epoch 176/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1153 - val_loss: 0.1135\n",
      "Epoch 177/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1143 - val_loss: 0.1126\n",
      "Epoch 178/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1134 - val_loss: 0.1117\n",
      "Epoch 179/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1126 - val_loss: 0.1109\n",
      "Epoch 180/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1117 - val_loss: 0.1101\n",
      "Epoch 181/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1109 - val_loss: 0.1093\n",
      "Epoch 182/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1102 - val_loss: 0.1086\n",
      "Epoch 183/500\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.1095 - val_loss: 0.1080\n",
      "Epoch 184/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1089 - val_loss: 0.1074\n",
      "Epoch 185/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1083 - val_loss: 0.1068\n",
      "Epoch 186/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1077 - val_loss: 0.1063\n",
      "Epoch 187/500\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.1072 - val_loss: 0.1058\n",
      "Epoch 188/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1067 - val_loss: 0.1053\n",
      "Epoch 189/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1063 - val_loss: 0.1049\n",
      "Epoch 190/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1058 - val_loss: 0.1045\n",
      "Epoch 191/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1054 - val_loss: 0.1041\n",
      "Epoch 192/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1051 - val_loss: 0.1037\n",
      "Epoch 193/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1047 - val_loss: 0.1034\n",
      "Epoch 194/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1044 - val_loss: 0.1031\n",
      "Epoch 195/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1041 - val_loss: 0.1028\n",
      "Epoch 196/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1038 - val_loss: 0.1025\n",
      "Epoch 197/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1035 - val_loss: 0.1022\n",
      "Epoch 198/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1032 - val_loss: 0.1020\n",
      "Epoch 199/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1030 - val_loss: 0.1017\n",
      "Epoch 200/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1027 - val_loss: 0.1015\n",
      "Epoch 201/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1025 - val_loss: 0.1013\n",
      "Epoch 202/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1023 - val_loss: 0.1011\n",
      "Epoch 203/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1021 - val_loss: 0.1009\n",
      "Epoch 204/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1019 - val_loss: 0.1007\n",
      "Epoch 205/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1017 - val_loss: 0.1005\n",
      "Epoch 206/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1015 - val_loss: 0.1003\n",
      "Epoch 207/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1013 - val_loss: 0.1001\n",
      "Epoch 208/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1012 - val_loss: 0.0999\n",
      "Epoch 209/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1010 - val_loss: 0.0998\n",
      "Epoch 210/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1008 - val_loss: 0.0997\n",
      "Epoch 211/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1007 - val_loss: 0.0995\n",
      "Epoch 212/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1005 - val_loss: 0.0993\n",
      "Epoch 213/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1004 - val_loss: 0.0992\n",
      "Epoch 214/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1002 - val_loss: 0.0991\n",
      "Epoch 215/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1001 - val_loss: 0.0989\n",
      "Epoch 216/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1000 - val_loss: 0.0988\n",
      "Epoch 217/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0998 - val_loss: 0.0987\n",
      "Epoch 218/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0997 - val_loss: 0.0986\n",
      "Epoch 219/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0996 - val_loss: 0.0985\n",
      "Epoch 220/500\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0995 - val_loss: 0.0983\n",
      "Epoch 221/500\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0994 - val_loss: 0.0982\n",
      "Epoch 222/500\n",
      "32928/60000 [===============>..............] - ETA: 0s - loss: 0.0991"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c974f1ed31f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                verbose=True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compile & fit model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer ='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "               epochs=500,\n",
    "               batch_size=784,\n",
    "               shuffle=True,\n",
    "               validation_data=(x_test, x_test),\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Convolutional autoencoder\n",
    "\n",
    "> Since our inputs are images, it makes sense to use convolutional neural networks (convnets) as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders --they simply perform much better.\n",
    "\n",
    "> Let's implement one. The encoder will consist in a stack of Conv2D and MaxPooling2D layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of Conv2D and UpSampling2D layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# Create Model \n",
    "input_img = Input(shape=(28,28,1))\n",
    "\n",
    "x = Conv2D(16,(3,3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2,2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional representation\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.fit(x_train, x_train,\n",
    "#                epochs=100,\n",
    "#                batch_size=784,\n",
    "#                shuffle=True,\n",
    "#                validation_data=(x_test, x_test),\n",
    "#                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1113 19:02:30.364223 139806021412672 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c72724825502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 verbose=False)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# wandb.init(project=\"mnist_autoencoder\", entity=\"ds5\")\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of the Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "encoder.predict(x_train)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You will train an autoencoder at some point in the near future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval with Autoencoders (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A common usecase for autoencoders is for reverse image search. Let's try to draw an image and see what's most similiar in our dataset. \n",
    "\n",
    "To accomplish this we will need to slice our autoendoer in half to extract our reduced features. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "encoded_imgs = encoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=10, algorithm='ball_tree')\n",
    "nn.fit(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.kneighbors(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You should already be familiar with KNN and similarity queries, so the key component of this section is know what to 'slice' from your autoencoder (the encoder) to extract features from your data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "* <a href=\"#p1\">Part 1</a>: Describe the componenets of an autoencoder\n",
    "    - Enocder\n",
    "    - Decoder\n",
    "* <a href=\"#p2\">Part 2</a>: Train an autoencoder\n",
    "    - Can do in Keras Easily\n",
    "    - Can use a variety of architectures\n",
    "    - Architectures must follow hourglass shape\n",
    "* <a href=\"#p3\">Part 3</a>: Apply an autoenocder to a basic information retrieval problem\n",
    "    - Extract just the encoder to use for various tasks\n",
    "    - AE ares good for dimensionality reduction, reverse image search, and may more things. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "__References__\n",
    "- [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "- [Deep Learning Cookbook](http://shop.oreilly.com/product/0636920097471.do)\n",
    "\n",
    "__Additional Material__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
